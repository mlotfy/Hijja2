{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkTbewrvLn9KQFIxzpQOR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlotfy/Hijja2/blob/master/MLArabic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eyBme8aYorX",
        "outputId": "fdde736d-efbf-46a4-9e64-d066f897fe0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using:\n",
            "\t• TensorFlow version: 2.7.0\n",
            "\t• tf.keras version: 2.7.0\n",
            "\t• Running on GPU\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "#!/usr/bin/env python\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import regularizers\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "\n",
        "print('Using:')\n",
        "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
        "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
        "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#training_set, dataset_info = tfds.load('mnist', split='train', as_supervised = True, with_info = True)\n",
        "\n",
        "#b_size = 64\n",
        "\n",
        "train_df=pd.read_csv('https://raw.githubusercontent.com/mlotfy/Hijja2/master/code/data/X_train.csv')\n",
        "train_df_label=pd.read_csv('https://raw.githubusercontent.com/mlotfy/Hijja2/master/code/data/y_train.csv')\n",
        "\n",
        "test_df=pd.read_csv('https://raw.githubusercontent.com/mlotfy/Hijja2/master/code/data/X_test.csv')\n",
        "test_df_label=pd.read_csv('https://raw.githubusercontent.com/mlotfy/Hijja2/master/code/data/y_test.csv')\n",
        "#training_set = tf.data.experimental.make_csv_dataset('data\\X_train.csv',batch_size=b_size)\n",
        "#dataset_info= tf.data.experimental.make_csv_dataset('data\\y_train.csv',batch_size=b_size)\n",
        "\n",
        "\n",
        "#print(training_set)\n",
        "#print(dataset_info)\n",
        "def normalize(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "#for  labels in ds.take(1):\n",
        "#    print('The images in the training set have:\\n\\u2022 ', labels['pixel11'])\n",
        "num_training_examples = len(train_df)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_df.values.reshape(-1, 32, 32,1), train_df_label.to_numpy()))\n",
        "\n",
        "num_test_examples = len(test_df)\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_df.values.reshape(-1, 32, 32,1), test_df_label.to_numpy()))\n",
        "\n",
        "arabic_characters = ['0','alef أ', 'beh ب', 'teh ت', 'theh ث', 'jeem ج', 'hah ح', 'khah خ', 'dal د', 'thal ذ',\n",
        "                    'reh ر', 'zain ز', 'seen س', 'sheen ش', 'sad ص', 'dad ض', 'tah ط', 'zah ظ', 'ain ع',\n",
        "                    'ghain غ', 'feh ف', 'qaf ق', 'kaf ك', 'lam ل', 'meem م', 'noon ن', 'heh هـ', 'waw و', 'yeh ي','hamza ء']\n",
        "\n",
        "batch_size = 64\n",
        "#train_dataset = dataset.shuffle(len(train_df)).batch(1)\n",
        "training_batches = dataset.shuffle(num_training_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
        "\n",
        "testing_batches = dataset_test.shuffle(num_test_examples//4).batch(batch_size).map(normalize).prefetch(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "IKirtRYxZESw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fYNAruR1bAVs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "4P08-borZ0R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Solution\n",
        "\n",
        "layer_neurons = [2048,1024, 512, 256, 128, 56, 48,36, 72,42]\n",
        "#layer_neurons = [1024, 128, 42]\n",
        "my_model = tf.keras.Sequential()\n",
        "my_model.add(tf.keras.layers.Flatten(input_shape = (32, 32, 1)))\n",
        "\n",
        "for neurons in layer_neurons:\n",
        "    my_model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
        "    #my_model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "#my_model.add(Dense(30, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "#my_model.add(activation('linear'))\n",
        "\n",
        "my_model.add(tf.keras.layers.Dense(30, activation='softmax'))\n",
        "\n",
        "\n",
        "#my_model = tf.keras.Sequential([\n",
        "#           tf.keras.layers.Flatten(input_shape = (32,32,1)),\n",
        "#           tf.keras.layers.Dense(512, activation = 'relu'),\n",
        "#           #tf.keras.layers.Dropout(0.4),\n",
        "#           tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "#           tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "#           #tf.keras.layers.Dropout(0.4),\n",
        "#           tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "#           tf.keras.layers.Dense(45, activation = 'relu'),\n",
        "#           tf.keras.layers.Dense(30, activation = 'softmax')\n",
        "#])\n",
        "\n",
        "print(my_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AywWnCQZM75",
        "outputId": "9eeb111b-f367-4c8c-a6a2-fbc2353e5ef4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 56)                7224      \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 48)                2736      \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 36)                1764      \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 72)                2664      \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 42)                3066      \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 30)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,905,144\n",
            "Trainable params: 4,905,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "my_model.compile(optimizer='adam',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#my_model.compile(loss='binary_crossentropy',\n",
        "#              optimizer=sgd,\n",
        "#              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#for image_batch, label_batch in training_batches.take(1):\n",
        "#    loss, accuracy = my_model.evaluate(image_batch, label_batch)\n",
        "\n",
        "#print('\\nLoss before training: {:,.3f}'.format(loss))\n",
        "#print('Accuracy before training: {:.3%}'.format(accuracy))\n",
        "\n",
        "\n",
        "EPOCHS = 150\n",
        "\n",
        "early_stop=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss', patience=5, \n",
        " \n",
        ")\n",
        "\n",
        "\n",
        "history = my_model.fit(training_batches, epochs = EPOCHS, callbacks=[early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk3WlGhKZRPY",
        "outputId": "1c7c75fd-1e8e-42bd-faee-2e12a67d41cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "593/593 [==============================] - 6s 9ms/step - loss: 2.7253 - accuracy: 0.2003\n",
            "Epoch 2/150\n",
            "593/593 [==============================] - 5s 9ms/step - loss: 2.2054 - accuracy: 0.3174\n",
            "Epoch 3/150\n",
            "593/593 [==============================] - 5s 9ms/step - loss: 1.8263 - accuracy: 0.4200\n",
            "Epoch 4/150\n",
            "593/593 [==============================] - 5s 9ms/step - loss: 1.5324 - accuracy: 0.5045\n",
            "Epoch 5/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 1.3285 - accuracy: 0.5644\n",
            "Epoch 6/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 1.1469 - accuracy: 0.6245\n",
            "Epoch 7/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.9970 - accuracy: 0.6741\n",
            "Epoch 8/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.8669 - accuracy: 0.7143\n",
            "Epoch 9/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.7528 - accuracy: 0.7542\n",
            "Epoch 10/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.6650 - accuracy: 0.7809\n",
            "Epoch 11/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.5859 - accuracy: 0.8117\n",
            "Epoch 12/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.5086 - accuracy: 0.8393\n",
            "Epoch 13/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.4579 - accuracy: 0.8568\n",
            "Epoch 14/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.3889 - accuracy: 0.8768\n",
            "Epoch 15/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.3560 - accuracy: 0.8900\n",
            "Epoch 16/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.3344 - accuracy: 0.8981\n",
            "Epoch 17/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.2917 - accuracy: 0.9118\n",
            "Epoch 18/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.2710 - accuracy: 0.9193\n",
            "Epoch 19/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.2642 - accuracy: 0.9230\n",
            "Epoch 20/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.2328 - accuracy: 0.9322\n",
            "Epoch 21/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.2158 - accuracy: 0.9365\n",
            "Epoch 22/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.2029 - accuracy: 0.9413\n",
            "Epoch 23/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.1849 - accuracy: 0.9458\n",
            "Epoch 24/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.1812 - accuracy: 0.9491\n",
            "Epoch 25/150\n",
            "593/593 [==============================] - 5s 8ms/step - loss: 0.1790 - accuracy: 0.9491\n",
            "Epoch 26/150\n",
            "529/593 [=========================>....] - ETA: 0s - loss: 0.1564 - accuracy: 0.9557"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "for image_batch, label_batch in training_batches.take(1):\n",
        "    loss, accuracy = my_model.evaluate(image_batch, label_batch)\n",
        "\n",
        "print('\\nLoss after training: {:,.3f}'.format(loss))\n",
        "print('Accuracy after training: {:.3%}'.format(accuracy))\n",
        "\n",
        "for image_batch, label_batch in testing_batches.take(1):\n",
        "    loss, accuracy = my_model.evaluate(image_batch, label_batch)\n",
        "\n",
        "print('\\nLoss  Testing: {:,.3f}'.format(loss))\n",
        "print('Accuracy  Testing: {:.3%}'.format(accuracy))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "i=0\n",
        "for image_batch, label_batch in testing_batches.take(24):\n",
        "    ps = my_model.predict(image_batch)\n",
        "    first_image = image_batch.numpy().squeeze()[0]\n",
        "    i+=1\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(first_image, cmap = plt.cm.binary)\n",
        "    color = 'green' if np.argmax(ps[0]) == label_batch.numpy().squeeze()[0] else 'red'\n",
        "    plt.xlabel(arabic_characters[np.argmax(ps[0])], color=color)\n",
        "    #plt.title(arabic_characters[np.argmax(ps[0])], color=color)\n",
        "    #plt.xlabel( 'Actual -> ' + arabic_characters[label_batch.numpy().squeeze()[0]])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.legend([\"accuracy\",\"loss\"])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "23uMGsM_ZgAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Solution\n",
        "\n",
        "for image_batch, label_batch in testing_batches.take(1):\n",
        "    ps = my_model.predict(image_batch)\n",
        "    first_image = image_batch.numpy().squeeze()[0]\n",
        "    \n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(first_image, cmap = plt.cm.binary)\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(30), ps[0])\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(30))\n",
        "    ax2.set_yticklabels(arabic_characters)\n",
        "    ax2.set_title('Class Probability')\n",
        "    plt.title(arabic_characters[np.argmax(ps[0])]  +  ' -> ' + arabic_characters[label_batch.numpy().squeeze()[0]])\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    #plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wuQBketaZilL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_df = train_df.astype(float)\n",
        "test_df = test_df.astype(float)\n",
        "train_df/=255\n",
        "test_df /=255\n",
        "\n",
        "y_train_pred = my_model.predict(train_df.values.reshape(-1, 32, 32,1))\n",
        "y_test_pred = my_model.predict(test_df.values.reshape(-1, 32, 32,1))\n",
        "\n",
        "mse_train = ((y_train_pred - train_df_label.values) ** 2).mean()\n",
        "mse_test = ((y_test_pred - test_df_label.values) ** 2).mean()\n",
        "print(\"\\nSecond Opinion loss: %5.4f - val_loss: %5.4f\" % (mse_train, mse_test))\n",
        "\n",
        "my_model.save('./test_model5.h5')"
      ],
      "metadata": {
        "id": "rNqUNBDfZVGW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}